---
title: "Introduction to the Statistical Analysis of Microbiome Data in R"
author: "Nicholas Ollberding"
date: "7/15/2019"
output: 
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


#
<br>

The goal of this session is to provide you with a **high-level introduction** to some common analytic methods used to analyze microbiome data. It will also serve to introduce you several popular R packages developed specifically for microbiome data analysis.  We chose to emphasize R for this course because of the rapid development of methods and packages provided in the R language, the breadth of existing tutorials and resources, and the ever expanding community of R users.  However, other platforms such as [QIIME2](https://qiime2.org/), [biobakery](https://bitbucket.org/biobakery/biobakery/wiki/Home) and [USEARCH](https://www.drive5.com/usearch/), just to name a few, offer *excellent integrated solutions* for the processing and analysis of amplicon and/or shotgun metagenomic sequence data.


The diverse goals and technical variation of metagenomic research projects does not allow for a standard **“analytic pipeline”** for microbiome data analysis.  Approaching the analysis of microbiome data with a single workflow in mind is generally not a great idea, as there is no *“one size fits all”* solution for the assorted set of questions one might want to answer. However, you may be surprised to find that projects on very different topics often have overarching analytic aims such as:

  * Describing the microbial community composition of a set of samples
  * Estimating within- and between-sample diversity
  * Identifying differentially abundant taxa
  * Predicting a response from a set of taxonomic features
  * Assessing microbial network structures and patterns of co-occurance
  * Exploring the phylogenetic relatedness of a set of organisms  


We will cover statistical methods developed to address several of these aims with a focus on introducing you to their implementation in R.  A detailed description of each approach, its assumptions, package options, etc. is beyond the scope of this session. However, I try to provide links to source materials and more detailed documentation where possible.  **The statistical analysis of microbial metagenomic sequence data is a rapidly evolving field** and different solutions (often many) have been proposed to answer the same questions.  I have tried to focus on methods that are common in the microbiome literature, well-documented, and reasonably accessible...and a few I think are new and interesting. I also try to show a few different approaches in each section. In cases where I focus largely on more basic implementations, I have tried to provide links for advanced learning of more complex topics. 

<br>

The publicly available data used in this session are from Giloteaux et. al. [Reduced diversity and altered composition of the gut microbiome in individuals with myalgic encephalomyelitis/chronic fatigue syndrome](https://microbiomejournal.biomedcentral.com/articles/10.1186/s40168-016-0171-4) published in Microbiome (2016). The metadata, OTU table, and taxonomy files were obtained from the QIIME2 tutorial [Differential abundance analysis with gneiss](https://docs.qiime2.org/2019.4/tutorials/gneiss/) (accessed on 06/13/2019). The code and data used to generate the phyloseq object is provided on my [GitHub page](https://github.com/Nick243/Create-Giloteaux-2016-Phyloseq-Object). 
The data were generated by 16S rRNA gene sequencing (V4 hypervariable region) of fecal samples on the Illumina MiSeq. Our focus will be on examining differences in the microbiota of patients with chronic fatigue syndrome versus healthy controls.  We will examine:

  *	Taxonomic relative abundance
  *	Hierarchal clustering
  *	Alpha-diversity
  *	Beta-diversity
  *	Differential abundance testing
  *	Predicting class labels

<br>

# Additional resources
There are many great resources for conducting microbiome data analysis in R. [Statistical Analysis of Microbiome Data in R](https://www.springer.com/gp/book/9789811315336) by Xia, Sun, and Chen (2018) is an excellent textbook in this area.  For those looking for an end-to-end workflow for amplicon data in R, I highly recommend Ben Callahan’s F1000 Research paper [Bioconductor Workflow for Microbiome Data Analysis: from raw reads to community analyses](https://f1000research.com/articles/5-1492). In addition there are numerous websites and vignettes dedicated to microbiome analyses.  A few include:

  *	Paul McMurdie's phyloseq [website](https://joey711.github.io/phyloseq/)
  * Robert Edgar's [website](https://www.drive5.com/usearch/manual/)
  * The microbiome R package [website](https://microbiome.github.io/microbiome/)
  * All the materials and resources posted on the STAMPS [wiki page]( https://github.com/mblstamps/stamps2018/wiki) (a course I highly recommend!) 

<br>


# Installing packages

The code below will install the packages needed to run the analyses. These packages are installed from [CRAN]( https://cran.r-project.org/), [Bioconductor]( https://www.bioconductor.org/) and from developer [GitHub]( https://github.com/) sites. Several of these packages are large, and have many dependencies, so this will take some time. This code was modified from Ben's Bioconductor paper. 

In general, package management and versioning can be a challenge for those new to R.  Inevitably, if you do not take steps ahead of time, you will find that one of your programs that ran fine just a few months ago, no longer works! Often this is because changes in new versions of packages or R caused your code to break.  There are multiple solutions depending on your goals, and all come with pros and cons, but a good place to start is to learn more about [Packrat]( https://rstudio.github.io/packrat/) and other package management tools.    

 If you already have many/some of these packages installed on your local system, you may want to skip this step and install manually only those that you need.

```{r install, eval = FALSE}
.cran_packages <- c("tidyverse", "cowplot", "picante", "vegan", "HMP", "dendextend", "rms", "devtools")

.bioc_packages <- c("phyloseq", "DESeq2", "microbiome", "metagenomeSeq", "ALDEx2")


.inst <- .cran_packages %in% installed.packages()
if(any(!.inst)) {
  install.packages(.cran_packages[!.inst])
}


if (!requireNamespace("BiocManager", quietly = TRUE))
  install.packages("BiocManager")
BiocManager::install(.bioc_packages, version = "3.9")


devtools::install_github("adw96/breakaway")
devtools::install_github(repo = "UVic-omics/selbal")

```


<br>

# Loading required packages

Let's load the required packages.  This is not the most elegant way to do this, but it allows you to see each package that is loaded and the version number.   

```{r load, message=FALSE, warning=FALSE}
library(tidyverse); packageVersion("tidyverse")                 
library(phyloseq); packageVersion("phyloseq")                    
library(DESeq2); packageVersion("DESeq2")                        
library(microbiome); packageVersion("microbiome")               
library(vegan); packageVersion("vegan")                          
library(picante); packageVersion("picante")                       
library(ALDEx2); packageVersion("ALDEx2")                        
library(metagenomeSeq); packageVersion("metagenomeSeq")          
library(HMP); packageVersion("HMP")                              
library(dendextend); packageVersion("dendextend")                
library(selbal); packageVersion("selbal")                          
library(rms); packageVersion("rms")
library(breakaway); packageVersion("breakaway")                  
```


<br>

# Reading in the Giloteaux data

The data from the **Giloteaux et. al. 2016 paper** has been saved as a phyloseq object.  We will use the readRDS() function to read it into R.  We will also examine the distribution of read counts (per sample library size/read depth/total reads) and remove samples with < 5k total reads.  We will then create a new metadata field "Status" that provides more "descriptive" values for our primary variable of interest; whether or not the sample was from a patient with chronic fatigue syndrome or a healthy control. 

This should all be familiar to those of you who worked through the [Introduction to Phyloseq](https://github.com/Nick243/Introduction-to-Metagenomics-Summer-Workshop-2019) session. However, something that will be new is that now we are using pipes from the [magrittr package](https://magrittr.tidyverse.org/) and [tidyverse](https://www.tidyverse.org/) verbs to streamline some of the data manipulation steps. *For those of you have not worked with the tidyverse set of packages and functions you are missing out!* They will change they way you work in R. [R for Data Science](https://r4ds.had.co.nz/) is an excellent source to learn more about the tidyverse packages and philosophy for data science.  

**Additional quality controls checks and data pre-processing specific to the goals of your project should be conducted at this point (but is outside of the scope of the current session).**  

```{r load data}
#Read in ps object
(ps <- readRDS("ps_giloteaux_2016.rds"))

#Sort samples on total read count, remove <5k reads, remove any OTUs seen in only those samples
sort(phyloseq::sample_sums(ps)) 
(ps <- phyloseq::subset_samples(ps, phyloseq::sample_sums(ps) > 5000)) 
(ps <- phyloseq::prune_taxa(phyloseq::taxa_sums(ps) > 0, ps)) 


#Assign new sample metadata field
phyloseq::sample_data(ps)$Status <- ifelse(phyloseq::sample_data(ps)$Subject == "Patient", "Chronic Fatigue", "Control")
phyloseq::sample_data(ps)$Status <- factor(phyloseq::sample_data(ps)$Status, levels = c("Control", "Chronic Fatigue"))
ps %>% 
  sample_data %>%
  dplyr::count(Status)
```
  
We can see that we have a phyloseq object consisting of 138 taxa on 84 samples, 22 sample metadata fields, 7 taxonomic ranks and that a phylogenetic tree and the reference  sequences have been included. We also see that there are data on n=37 controls and n=47 patients with chronic fatigue.

<br>


# Visualizing relative abundance

Often an early step in many microbiome projects to visualize the relative abundance of organisms at specific taxonomic ranks. Stacked bar plots and faceted box plots are two ways of doing this. I recommend that if using bar plots to include each sample as a separate observation (and not to aggregate by groups).  This is because the sample-to-sample variability can be high, even within groups, which may be just or more important to observe than between-group differences…which can be obscured with aggregation. 

The ability to discriminate between more than say a dozen colors in a single plot is also a limitation of the stacked bar plot (faceted box plots do not suffer this limitation). Thus, this is one analysis I often run in QIIME2 using the [taxa barplot command](https://docs.qiime2.org/2019.4/tutorials/moving-pictures/), as it allows for beautiful [interactive viewing](https://view.qiime2.org/visualization/?type=html&src=https%3A%2F%2Fdocs.qiime2.org%2F2019.4%2Fdata%2Ftutorials%2Fmoving-pictures%2Ftaxa-bar-plots.qzv). This could also be done in R using a [shiny app](https://shiny.rstudio.com/).  I just haven’t implemented, or seen others implement, this functionality yet in R (I imagine someone has so please let me know if/when you do).

Here we will agglomerate the reads to the phylum-level using phyloseq and plot the relative abundance by Status.

```{r bar plot}
#Get count of phyla
table(phyloseq::tax_table(ps)[, "Phylum"])

#Convert to relative abundance
ps_rel_abund = phyloseq::transform_sample_counts(ps, function(x){x / sum(x)})
phyloseq::otu_table(ps)[1:5, 1:5]
phyloseq::otu_table(ps_rel_abund)[1:5, 1:5]

#Plot
phyloseq::plot_bar(ps_rel_abund, fill = "Phylum") +
  geom_bar(aes(color = Phylum, fill = Phylum), stat = "identity", position = "stack") +
  labs(x = "", y = "Relative Abundance\n") +
  facet_wrap(~ Status, scales = "free") +
  theme(panel.background = element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())

```

There are a total of nine phyla and their relative abundance looks to be quite simialr between groups. You could sort the taxa on abundance to improve the vizualization. I'll let you give that a shot on your own. Let's generate box plots according to group and facet them by phylum using the raw counts. We will use the phyloseq::melt function to help.

<br>

```{r box plot, fig.height = 8, fig.width = 12, fig.align = "center"}
#Agglomerate to phylum-level and rename
ps_phylum <- phyloseq::tax_glom(ps, "Phylum")
phyloseq::taxa_names(ps_phylum) <- phyloseq::tax_table(ps_phylum)[, "Phylum"]
phyloseq::otu_table(ps_phylum)[1:5, 1:5]

#Melt and plot
phyloseq::psmelt(ps_phylum) %>%
ggplot(data = ., aes(x = Status, y = Abundance)) +
  geom_boxplot(outlier.shape  = NA) +
  geom_jitter(aes(color = OTU), height = 0, width = .2) +
  labs(x = "", y = "Abundance\n") +
  facet_wrap(~ OTU, scales = "free")

```

As we saw before, many samples have a high number of Firmicutes, followed by Bacteroidetes, and Actinobacteria.  Most samples have low read counts for other phyla with some outlying samples. There does not appear to be much difference in the major phyla between groups. Check out Ben Callahan's [F1000 paper]( https://f1000research.com/articles/5-1492) for additional examples on visualizing sequence variant prevalence/abundance that may be helpful for specific analyses. 

One way to formally test for a difference in the phylum-level abundance is to conduct a multivariate test for differences in the overall composition between groups of samples. This type of test can be implemented using the [HMP package](https://cran.r-project.org/web/packages/HMP/index.html) (Xdc.sevsample function) described in the paper [Hypothesis Testing and Power Calculations for Taxonomic-Based Human Microbiome Data](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0052078) by La Rosa et. al.

Basically, a [Dirichlet-Multinomial distribution](https://en.wikipedia.org/wiki/Dirichlet-multinomial_distribution) is assumed for the data and null hypothesis testing is conducted by testing for a difference in the location (mean distribution of each taxa) across groups accounting for the overdispersion in the count data. The authors describe this test is analogous to a two sample t-test, but instead we are evaluating whether taxa frequencies observed in both groups of metagenomic samples are equal (null hypothesis). Here we are performing the test on bacterial phyla, but it could be performed **at any taxonomic level** including OTUs. The authors recommend that rare taxa be pooled into a single group to improve testing. 

```{r hmp}
#Subset groups
controls <- phyloseq::subset_samples(ps_phylum, Status == "Control")
cf <- phyloseq::subset_samples(ps_phylum, Status == "Chronic Fatigue")

#Output OTU tables
control_otu <- data.frame(phyloseq::otu_table(controls))
cf_otu <- data.frame(phyloseq::otu_table(cf))

#Group rare phyla
control_otu <- control_otu %>%
  t(.) %>%
  as.data.frame(.) %>%
  mutate(Other = Cyanobacteria + Euryarchaeota + Tenericutes + Verrucomicrobia + Fusobacteria) %>%
  dplyr::select(-Cyanobacteria, -Euryarchaeota, -Tenericutes, -Verrucomicrobia, -Fusobacteria)

cf_otu <- cf_otu %>%
  t(.) %>%
  as.data.frame(.) %>%
  mutate(Other = Cyanobacteria + Euryarchaeota + Tenericutes + Verrucomicrobia + Fusobacteria) %>%
  dplyr::select(-Cyanobacteria, -Euryarchaeota, -Tenericutes, -Verrucomicrobia, -Fusobacteria)

#HMP test
group_data <- list(control_otu, cf_otu)
(xdc <- HMP::Xdc.sevsample(group_data))           
1 - pchisq(.2769004, 5)

```

The HMP test fails to reject the null hypothesis of no difference in the distribution of phyla between groups (in line with our expectations). The xdc test follows a Chi-square distribution with degrees of freedom equal to (J-1)*K, where J is the number of groups and K is the number of taxa. The last calculation just shows how the p-value is obtained. The test can be expanded to more than two groups and to test for differences in rank abundance distributions (RAD).  These are topics I encourage you to explore on your own.

The microbiome package also has some nice functions for visualizing [community composition](http://microbiome.github.io/microbiome/Composition.html) you should look into. 

<br>


# Hierarchical clustering

Another early step in many microbiome projects to examine how samples cluster on some measure of taxonomic (dis)similarity. There are **MANY** ways to do perform such clustering. Here I present just one approach that I assume many of you are familiar with.  We will perform hierarchal clustering of samples based on their Bray-Curtis dissimilarity. Bray-Curtis dissimilarity quantifies the compositional dissimilarity between two different sites based on the counts at each site. Here is a link to how it is [calculated](https://en.wikipedia.org/wiki/Bray%E2%80%93Curtis_dissimilarity). We will discuss this in more detail during the lecture, but for now it should suffice to know that the **as two samples share fewer taxa, the number increases.**  The Bray-Curtis dissimilarity is zero for samples that have the exact same composition and one for those sharing no taxa. It is also worth remembering that this is a measure of dissimilarity (it is not a true distance measure).    

We will use the popular [vegan package]( https://www.rdocumentation.org/packages/vegan/versions/2.4-2) for community ecology to compute the Bray-Curtis dissimilarity for all samples.  Then we will apply Ward's clustering and color code the sample names to assess the extent to which the samples from the control and chronic fatigue participants cluster. At a high-level, Ward's clustering finds the pair of clusters at each iteration that minimalizes the increase in total variance. 

Let's see how this is done in R. 

```{r wards, fig.height = 8, fig.width = 16, fig.align = "center"}
#Extract OTU table and compute BC
ps_rel_otu <- data.frame(phyloseq::otu_table(ps_rel_abund))
ps_rel_otu <- t(ps_rel_otu)
bc_dist <- vegan::vegdist(ps_rel_otu, method = "bray")
as.matrix(bc_dist)[1:5, 1:5]

#Save as dendrogram
ward <- as.dendrogram(hclust(bc_dist, method = "ward.D2"))

#Provide color codes
meta <- data.frame(phyloseq::sample_data(ps_rel_abund))
colorCode <- c(Control = "red", `Chronic Fatigue` = "blue")
labels_colors(ward) <- colorCode[meta$Status][order.dendrogram(ward)]

#Plot
plot(ward)

```

We can see that the Bray-Curtis dissimilarity for these selected samples range from around 0.6 to close to 1. Thus, the composition of some samples are quite different from one another. We also see some clustering according to Status near the tips, but no clear "higher-level" clustering. We will try to exploit this information later to see if we can predict the label of each sample with only information on the microbial relative abundances. 

Heatmaps are another good way to visualize these types of associations and can be implemented using [phyloseq]( https://joey711.github.io/phyloseq/plot_heatmap-examples.html). Give it a try on your own! 

<br>


# Alpha-diversity

Robert Edgar provides an excellent definition of alpha-diversity on his [website](https://www.drive5.com/usearch/manual/alpha_diversity.html):

>Alpha-diversity is the diversity in a single ecosystem or sample. The simplest measure is richness, the number of species (or OTUs) observed in the sample. Other metrics consider the abundances (frequencies) of the OTUs, for example to give lower weight to lower-abundance OTUs.

Basically, it is the within-sample diversity and includes how many organisms are observed (i.e. observed OTUs) and how evenly they are distributed. Many researchers are interested in estimating alpha-diversity since differences between groups have been associated with several health related outcomes. **However the issue of how to best estimate these quantities using data derived from next-generation sequencing (NGS) is controversial.** This is due to two main reasons:

1. The observed richness in a sample/site is typically underestimated due to inexhaustive sampling.  Thus, valid estimators of diversity require extrapolating from the available observations to provide estimates of the unobserved taxa (and also account for the sampling variability).
2. Extrapolation estimators require an accurate count of the rare taxa (including singletons) in each sample...which for NGS-based metagenomics studies we typically do not have...since singletons generally cannot be differentiated from sequencing errors using the current best informatics workflows. The extent to which we cannot accurately detect low abundance taxa limits the utility of diversity estimators reliant upon such counts. 

*So we are kind of in a catch-22 regarding the best way forward given current technologies.* 


It has been argued; however, that diversity metrics can nevertheless be compared between samples because the errors and biases **are mostly systematic** (i.e. occur with similar rates in all samples). See Dr. Edgar's discussion of the topic [here](https://www.drive5.com/usearch/manual/diversity_metrics_compare_groups.html) for more detail. This is what is typically done in most published studies to date.  A major underlying assumption here is that abundance structures are the same for the two groups being compared. This is perhaps a reasonable assumption when comparing similar environments, but it is hard to know without exhaustive sampling. See figure 1 [here](https://www.biorxiv.org/content/biorxiv/early/2017/12/11/231878.full.pdf) and the related discussion by Amy Willis for a more detailed understanding of how the abundance structure can lead you to incorrect conclusions (quite disconcerting).    

Rarefaction (subsampling reads from each sample without replacement to a constant depth) is often performed before estimating alpha-diversity; although, it is unclear to me if/when this helps since *environments can be identical with respect to one alpha diversity metric, but the different abundance structures will induce different biases when rarified* (italicized text taken from Amy's paper linked to above).

Dr. Willis has examined this issue in depth and developed [breakaway](https://github.com/adw96/breakaway) and [DivNet](https://github.com/adw96/DivNet) to specifically address the shortcoming of current approaches. I highly recommend you check out her [GitHub site](https://github.com/adw96). In a recent [paper](https://www.biorxiv.org/content/biorxiv/early/2017/12/11/231878.full.pdf) she argues:

>In order to draw meaningful conclusions about the entire microbial community, it is necessary to adjust for inexhaustive sampling using statistically-motivated parameter estimates for alpha diversity. In order to draw meaningful conclusions regarding comparisons of microbial communities, it is necessary to use measurement error models to adjust for the uncertainty in the estimation of alpha diversity.

She also states that breakaway is not *overly sensitive* to singleton counts.

The links below provide a brief introduction to the topic.  I look forward to Amy's updated tutorial and thoughts on when microbial diversity estimation is, and isn't, possible as mentioned in the last link *(I suspect it will result in some updating of these materials)*.

* <https://www.drive5.com/usearch/manual/alpha_diversity.html>
* <https://www.biorxiv.org/content/biorxiv/early/2017/12/11/231878.full.pdf>
* <https://github.com/benjjneb/dada2/issues/103>
* <https://github.com/benjjneb/dada2/issues/317>

<br>

Below we will estimate and test for differences according to chronic fatigue status using the plug-in estimates for observed richness, Shannon diversity, and phylogenetic diversity on the subsampled data (since this is common practice).  I have also provided some code to estimate richness using breakaway that you can examine on your own. I plan to update this section with some data that is more appropriate for breakaway. So check back soon.    
```{r read plot}
ggplot(data = data.frame("total_reads" =  phyloseq::sample_sums(ps),
                         "observed" = phyloseq::estimate_richness(ps, measures = "Observed")[, 1]),
       aes(x = total_reads, y = observed)) +
  geom_point() +
  geom_smooth(method="lm", se = FALSE) +
  labs(x = "\nTotal Reads", y = "Observed Richness\n")

```

<br>

We see that the observed OTUs are correlated with the total read count (as expected). Now let's subsample, plot, and test for group differences. 

```{r alpha}
#Subsample reads
(ps_rare <- phyloseq::rarefy_even_depth(ps, rngseed = 123, replace = FALSE))             
head(phyloseq::sample_sums(ps_rare))

#Generate a data.frame with adiv measures
adiv <- data.frame(
  "Observed" = phyloseq::estimate_richness(ps_rare, measures = "Observed"),
  "Shannon" = phyloseq::estimate_richness(ps_rare, measures = "Shannon"),
  "PD" = picante::pd(samp = data.frame(t(data.frame(phyloseq::otu_table(ps_rare)))), tree = phyloseq::phy_tree(ps_rare))[, 1],
  "Status" = phyloseq::sample_data(ps_rare)$Status)
head(adiv)

#Plot adiv measures
adiv %>%
  gather(key = metric, value = value, c("Observed", "Shannon", "PD")) %>%
  mutate(metric = factor(metric, levels = c("Observed", "Shannon", "PD"))) %>%
  ggplot(aes(x = Status, y = value)) +
  geom_boxplot(outlier.color = NA) +
  geom_jitter(aes(color = Status), height = 0, width = .2) +
  labs(x = "", y = "") +
  facet_wrap(~ metric, scales = "free") +
  theme(legend.position="none")

#Summarize
adiv %>%
  group_by(Status) %>%
  dplyr::summarise(median_observed = median(Observed),
            median_shannon = median(Shannon),
            median_pd = median(PD))

#Wilcoxon test of location
wilcox.test(Observed ~ Status, data = adiv, exact = FALSE, conf.int = TRUE)
wilcox.test(Shannon ~ Status, data = adiv, conf.int = TRUE)              
wilcox.test(PD ~ Status, data = adiv, conf.int = TRUE)


```

Here we see a modestly lower median alpha-diversity in samples from participants with chronic fatigue when compared to healthy controls. However, the variation in alpha-diversity between groups is highly overlapping and we fail to reject the null hypothesis of no difference in location between groups.

<br>

Below is the code to estimate richness using breakaway. You will see some warnings.  I plan to update this section with some additional data so check back soon.


```{r break, eval = FALSE}

#Obtain breakaway estimates
ba_adiv <- breakaway::breakaway(ps)
ba_adiv[1]

#Plot estimates
plot(ba_adiv, ps, color = "Status")     

#Examine models
summary(ba_adiv) %>%
  add_column("SampleNames" = ps %>% otu_table %>% sample_names)  

#Test for group differnce
bt <- breakaway::betta(summary(ba_adiv)$estimate,
                       summary(ba_adiv)$error,
                       make_design_matrix(ps, "Status"))
bt$table                                                        

```


<br>

# Beta-diversity

**Beta-diversity provides a measure of similarity, or dissimilarity, of one microbial composition to another.**  Beta-diversity is typically calculated on the OTU/ASV/species composition tables directly (after normalization), but can be calculated using abundances at higher taxonomic levels. One common estimator of microbial beta-diversity is the pairwise [Euclidean distance]( https://en.wikipedia.org/wiki/Euclidean_distance) between samples. However, many ecologically informative measures are also commonly used and include:

  * Bray-Curtis similarity
  * Jaccard similarity
  * Yue & Clayton theta similarity
  * [UniFrac distance](https://aem.asm.org/content/71/12/8228) 
  * **AND MANY MORE**
  
Pat Schloss provides a listing and links to a large number of alpha- and beta-diversity estimators on his [mothur wiki page](https://mothur.org/wiki/Calculators). He also offers [workshops](https://www.mothur.org/wiki/Workshops) on using mothur for processing amplicon sequence data and on using R for microbial ecologists a few times a year that I highly recommend.

This is probably a good time to touch on **count normalization.**  One of the challenges we face working with NGS-derived sequence data is that *the total number of reads for each sample is not directly tied to the starting quantity of DNA.* You can think of the total reads (to a reasonable approximation) as getting assigned by a random sampling process where some samples just get doled out more reads. Thus, the **total count does not carry any information on the absolute abundance of taxa.** As long as the count is sufficiently large, it is just a factor that we want to account for in our analysis and is not of particular interest other than differences across samples can be a source of bias.  Paul McMurdie provides an excellent discussion of the various goals and some approaches for normalization in his chapter on [Normalization of Microbiome Profiling Data](https://experiments.springernature.com/articles/10.1007/978-1-4939-8728-3_10) in the first edition of [Microbiome Analysis](https://www.springer.com/us/book/9781493987269?gclid=Cj0KCQjw3uboBRDCARIsAO2XcYCprgmMyNEyKBS0QWmqNSUSfbZ8yiN29s1HjVYYGx3T7Z-Qmylv5x8aAoRLEALw_wcB). [Weiss et. al.](https://microbiomejournal.biomedcentral.com/articles/10.1186/s40168-017-0237-y) also provide a great introduction and examination of the impact of normalization approaches on beta-diversity ordinations and differential abundance testing.

Here we will consider two approaches for library size normalization.  The first will employ a **compositional data analysis approach** and involves working with log-ratios.  The second will involve simply subsampling the data without replacement; however, this approach comes with [limiations](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003531). We will use it here as the authors of the UniFrac method have suggested that rarefying more clearly clusters samples according to biological origin than other normalization techniques do for ordination metrics based on presence or absence (i.e. unweighted UniFrac). 

A detailed discussion of compositional data analysis (CoDA) is beyond the scope of this session. I plan to add a tutorial devoted to CoDA in the future so check back.  **At a high-level** compositional data (i.e. data that carry only relative information and are constrained by a unit sum) exist in a restricted subspace of the Euclidian geometry referred to as the D-1 simplex *(I know this doesn't feel high-level)*. Due to this constraint, these data fail to meet many of the assumptions of our favorite statistical methods developed for unconstrained random variables.  Working with ratios of compositional elements lets us transform these data to the Euclidian space and apply our favorite methods (so we don’t need to work in the simplex).  Working with their logarithms makes them easier to interpret. There are different types of log-ratio “transformations” including the additive log-ratio, centered log-ratio, and isometric log-ratio transforms. Below are some great resources for learning more about compositional data analysis:

  *[Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011) by Quinn et. al. in Bioinformatics (2018)
  
  *[Statistical Analysis of Microbiome Data with R - Ch. 10](https://www.springer.com/us/book/9789811315336?gclid=Cj0KCQjw3uboBRDCARIsAO2XcYAphJ23am-AoIBh18HoW-WpAd8TwbQUEhc_DJV9gM-zWYtXe0-6l8saAkNHEALw_wcB)
  
  *[Applied Compositional Data Analysis](https://www.springer.com/gp/book/9783319964201) by Filzmoser, Hron, and Templ (2018) 
  
  *[Analyzing Compositional Data with R](https://www.springer.com/gp/book/9783642368080) by Boogaart and Tolosana-Delgado (2013) 
  
<br>
  
Below we generate a beta-diversity ordination using the Aitchison distance. This is simply applying PCA to the [centered log-ratio](https://en.wikipedia.org/wiki/Compositional_data#Center_logratio_transform) (CLR) transformed counts. We will use the microbiome package to do this and assign a pseudocount of 1 to facilitate the transformation (since the log of zero is undefined). There are alternative/better approaches than using a pseudocount and we will examine one in the next section. First we perform the transformation.

```{r transform clr}
#CLR transform
(ps_clr <- microbiome::transform(ps, "clr"))          
phyloseq::otu_table(ps)[1:5, 1:5]
phyloseq::otu_table(ps_clr)[1:5, 1:5]

```

We can see that the values are now no longer counts, but rather the dominance (or lack thereof) for each taxa relative to the geometric mean of all taxa on the logarithmic scale (any log base could be used and often log2 or log10 may aid in interpretation).

<br>

Now we will conduct the PCA, examine the relative importance of each principal component, and generate the ordination. **PCA is an unsupervised learning approach** that can help us see similarities between samples when there are a large number of features. Scatter plots are not much help here in high-dimensions since the number of possible plots is equal to p(p-1)^2^ where p = the number of features (quickly becomes intractable). So we need to find an approach that will let us map these data to a lower-dimensional space.  This is what PCA does.  It identifies latent variables referred to as principal components (PC) that capture as much of the information as possible...where information is the amount of variation in the data. We can then focus on those PCs that are most interesting (i.e. explain the most variation; give us the best lower-dimensional mapping). Given we can only visualize our samples in 2- or 3-dimenstional space, most microbiome studies only plot the data using either the first couple of PCs. A more though introduction to PCA can be found in the textbook [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/) by James, Witten, Hastie, and Tibshirani (2013). Let's give it a try!

```{r pca scree, fig.height = 8, fig.width = 12, fig.align = "center"}
#PCA via phyloseq
ord_clr <- phyloseq::ordinate(ps_clr, "RDA")

#Plot scree plot
phyloseq::plot_scree(ord_clr) + 
  geom_bar(stat="identity", fill = "blue") +
  labs(x = "\nAxis", y = "Proportion of Variance\n")

#Examine eigenvalues and % prop. variance explained
head(ord_clr$CA$eig)                                                  
sapply(ord_clr$CA$eig[1:5], function(x) x / sum(ord_clr$CA$eig))     

```

RDA without constraints is PCA...and we can generate the PCs using the phyloseq::ordinate function. A scree plot is then used to examine the proportion of total variation explained by each PC.  Here we see that the first PC really stands out and then we have a gradual decline for the remaining components. You may hear people talk about looking for the "elbow" in the plot where the information plateaus to select the number of PCs to retain.  Below we plot the first two components and scale the plot to reflect the relative amount of information explained by each axis as recommended by Nguyen and Holmes in their paper [Ten quick tips for effective dimensionality reduction](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006907).


<br>

```{r plot pca}
#Scale axes and plot ordination
clr1 <- ord_clr$CA$eig[1] / sum(ord_clr$CA$eig)
clr2 <- ord_clr$CA$eig[2] / sum(ord_clr$CA$eig)
phyloseq::plot_ordination(ps, ord_clr, type="samples", color="Status") + 
  geom_point(size = 2) +
  coord_fixed(clr2 / clr1) +
  stat_ellipse(aes(group = Status), linetype = 2)

```

We see some separation between the chronic fatigue and healthy controls samples suggesting some differences in the communities according to sample type. There is also a fair degree of overlap as is often seen in clinical research studies examining the same environment in two different patient populations. While PCA is an exploratory data visualization tool, we can test whether the samples cluster beyond that expected by sampling variability using [permutational multivariate analysis of variance](http://cc.oulu.fi/~jarioksa/softhelp/vegan/html/adonis.html) (PERMANOVA). It does this by partitioning the sums of squares for the within- and between-cluster components using the concept of centroids. Many permutations of the data (i.e. random shuffling) are used to generate the null distribution. The test from ADONIS can be confounded by differences in dispersion (or spread)…so we want to check this as well.

<br>

```{r adonis}
#Generate distance matrix
clr_dist_matrix <- phyloseq::distance(ps_clr, method = "euclidean") 

#ADONIS test
vegan::adonis(clr_dist_matrix ~ phyloseq::sample_data(ps_clr)$Status)

#Dispersion test and plot
dispr <- vegan::betadisper(clr_dist_matrix, phyloseq::sample_data(ps_clr)$Status)
dispr
plot(dispr, main = "Ordination Centroids and Dispersion Labeled: Aitchison Distance", sub = "")
boxplot(dispr, main = "", xlab = "")
permutest(dispr)
````

We reject the null hypothesis of no difference in the centroid location according to Status. However, the proportion of variance explained is quite small. You might get slightly different numbers.  This is because of the random process generating the permutations. There is a suggestion that the dispersion is greater in samples from patients with chronic fatigue syndrome. However, it does not exceed that expected by sampling variablilty at this sample size.

As has been explained by others (Xia, Sun, and Chen; Ch 7.4), I want to mention that this type of testing is akin to **attempting to "explain" the axes** using metadata fields. A more formal approach to hypotheses testing can be done using *redundancy analysis or canonical correspondence analysis* that directly uses information on metadata fields when generating the ordinations and conducting testing. These approaches *directly* test hypotheses about environmental variables.  I will not demonstrate these approaches here, but they can be computed using some of these same commands with minor modifications.

Lastly, I want to show you how you can bring in information the form of a phylogenic tree into beta-diversity analysis. The **UniFrac metric** incorporates phylogenic information by calculating the total branch lengths "unshared" between two samples divided by the total branch length. This approach often reveals interesting differences in the phylogenic relatedness between samples and sample types. Here we compute the weighted and unweighted UniFrac metrics using PCoA. PCoA can be thought of as PCA for non-Euclidian measures.


```{r plot unifrac, fig.height = 8, fig.width = 16, fig.align = "center"}
#Generate distances
ord_unifrac <- ordinate(ps_rare, method = "PCoA", distance = "wunifrac") 
ord_unifrac_un <- ordinate(ps_rare, method = "PCoA", distance = "unifrac")   

#Plot ordinations
a <- plot_ordination(ps_rare, ord_unifrac, color = "Status") + geom_point(size = 2)
b <- plot_ordination(ps_rare, ord_unifrac_un, color = "Status") + geom_point(size = 2)
cowplot::plot_grid(a, b, nrow = 1, ncol = 2, scale = .9, labels = c("Weighted", "Unweighted"))
```

There is a large amount of overlap between sample types for the weighted UniFrac distance (accounts for the relative abundance of each of the taxa within the communities).  However, there is clustering on at least the first axis for the unweighted UniFrac distance that is not "explained" by Status.  *Is there a metadata field in the data that reflects this separation?* I'll let you explore on your own. 

<br>

# Differential abundance testing

The goal of differential abundance testing is to **identify specific taxa associated with clinical metadata variables of interest.** This is a difficult task.  It is also one of the more controversial areas in microbiome data analysis. Some of the reasons for this are described in a recent paper by James Morton et. al. in [Nature Communications](https://www.nature.com/articles/s41467-019-10656-5) (2019), but is related to concerns that normalization and testing approaches have generally failed to control false discovery rates [(here is a good example)](https://academic.oup.com/bib/article-abstract/20/1/210/4091293?redirectedFrom=fulltext) and this has contributed to the lack of reproducibility in microbiome studies.  If you think about it for a moment, a couple of  difficulties come to mind:

* The goal of this type of analysis is to identify taxa that differ the most between conditions (or along a continuous gradient). Basically, we are identifying the most extreme results in the data. We would therefore **expect some/many/most of these findings to have been "outlying" results simply due to chance sampling variation** and to perhaps [regress back towards the mean/null value](https://en.wikipedia.org/wiki/Regression_toward_the_mean) when tested in a new sample of patients.
* The data are compositional and thus changes in one or more taxa can make it look like other/all taxa are changing.  James Morton has an excellent example of this [here](https://docs.qiime2.org/2019.4/tutorials/gneiss/). Methods that don't properly account of the compositional nature of the data can have [very high false discovery rates.](https://microbiomejournal.biomedcentral.com/articles/10.1186/s40168-016-0208-8).
* Functionally redundant taxa may serve the same "niche" in different environments or populations causing different taxa to be identified as differentially abundant across samples (however the testing approach would not be what is misleading here).
* The high correlation between many taxa may cause different, but highly correlated, features to be selected in different studies. 

Professor Frank Harrell provides a great overview of this general concern in Chapter 20 of his [Biostatistics for Biomedical Research](http://hbiostat.org/doc/bbr.pdf) online text. For general thoughts on statistics and predictive modeling I highly recommend that you check out his [blog](https://www.fharrell.com/#links) and [regression modeling strategies](http://biostat.mc.vanderbilt.edu/wiki/Main/RmS) course notes.

Other fields have wrestled with similar problems and have introduced approaches such as the requirement of replicating results in multiple cohorts of patients prior to publication (or at least employing rigorous resampling approaches to gauge the reproducibility), analysis pre-specification, and focusing more on prediction than "naming names". For compositional data including external information in the form of external spike-ins or estimates of total abundance (such as estimating total microbial load using qPCR), working with ratios, limiting the emphasis on testing, and understanding the limits of compositional data are likely reasonable ways forward here. However, **none of these are a panacea.**  Methodologists working in the area of microbiome data analysis are addressing some of these issues, but there is still much work to be done. Two excellent recent papers you should check out include James Morton's paper above and this [preprint](https://www.biorxiv.org/content/10.1101/559831v1) in biorxiv by McLaren, Willis and Callahan (2019) explaining and modeling correctable bias in metagenomic sequence studies.  

In this section, I will present a two approaches for estimating differential abundance. The first is simply applying the non-paramedic Wilcoxon rank-sum test to each taxon. The second is a version of the Wilcoxon test developed for compositional NGS data. I chose these two approaches since they are commonly used in microbiome studies and I expect many of you will have some familiarity with the Wilcoxon test or (Gosset's) t-test. However, all results should be interpreted in light of the concerns raised above. I also include the use of a CoDA transform for both since there does seem to be some growing support that log-ratio methodologies may better control the false positive rate. 

Many researchers will apply the non-parametric Wilcoxon rank-sum test to each OTU/ASV/species after normalization.  We will do this here.  We will also use **nested data frames** as advocated by Hadley Wickham to keep the data and test results together in a single data.frame.  *At first, I found this approach a little strange.*  However, I have come to use it all the time. It is perhaps a bit overkill here, but a very helpful framework when you want to run many models and then save them together with the data and results (especially when they take a long time to run). Here is a [link to a complete description of the nested frame approach](https://r4ds.had.co.nz/many-models.html) in the R for Data Science book.  We also use the map function from purr.  This operates like a for loop, allowing us to iterate the test over each OTU, but with less coding. This is a big chunk of code.  I will talk you through it.  

```{r wilcox da}
#Generate data.frame with OTUs and metadata
ps_wilcox <- data.frame(t(data.frame(phyloseq::otu_table(ps_clr))))
ps_wilcox$Status <- phyloseq::sample_data(ps_clr)$Status

#Define functions to pass to map
wilcox_model <- function(df){
  wilcox.test(abund ~ Status, data = df)
}

wilcox_pval <- function(df){
  wilcox.test(abund ~ Status, data = df)$p.value
}

#Create nested data frames by OTU and loop over each using map 
wilcox_results <- ps_wilcox %>%
  gather(key = OTU, value = abund, -Status) %>%
  group_by(OTU) %>%
  nest() %>%
  mutate(wilcox_test = map(data, wilcox_model),
         p_value = map(data, wilcox_pval))                       

#Show results
head(wilcox_results)
head(wilcox_results$data[[1]])
wilcox_results$wilcox_test[[1]]
wilcox_results$p_value[[1]]

```

Here we can see that we have a tibble where:

* each OTU is a row
* the data column contains a tibble for each OTU that contains the CLR abundance and Status fields (i.e. seperate data.frame for each OTU)
* the wilcox_test column contains the results of each Wilcoxon test
* the p_value column contains the extracted p-value for each test

<br>

Now we will unnest the results, grab the OTU names and p-values, add the taxonomic labels, and calculate the FDR adjusted p-values.

```{r unnest}
#Unnesting
wilcox_results <- wilcox_results %>%
  dplyr::select(OTU, p_value) %>%
  unnest()

head(wilcox_results)

#Adding taxonomic labels
taxa_info <- data.frame(tax_table(ps_clr))
taxa_info <- taxa_info %>% rownames_to_column(var = "OTU")

#Computing FDR corrected p-values
wilcox_results <- wilcox_results %>%
  full_join(taxa_info) %>%
  arrange(p_value) %>%
  mutate(BH_FDR = p.adjust(p_value, "BH")) %>%
  filter(BH_FDR < 0.05) %>%
  dplyr::select(OTU, p_value, BH_FDR, everything())

#Printing results
print.data.frame(wilcox_results)  
```

Here we see that we have several Clostridiales organisms identified as differentially abundant.  Next, we might use bootstrap resampling to see how often these results replicated in subsets of the data and calculate a measure of effect size. However, we will not do that here.  Instead we will take a look at another approach that uses the Wilcoxon test on the CLR transformed data with some improvements in the treatment of zero values and presentation of effect size. 

<br>

**ANOVA-like differential expression (ALDEx2)** is a popular CoDA method for differential abundance testing. ALDEx2 can be run via a single command; however, there are several steps that are occurring in the background. **At a high-level**, the steps include:

* Generate a large number (here n=128) of posterior probabilities for the observance of each taxon (i.e. output many data.frames where the counts have been converted to proportions). This is done by Monte-Carlo sampling from a Dirichlet distribution with a small non-zero prior to deal with zeros. The total read count therefore only contributes to the precision of the proportions. 
* Apply the centered log-ratio transformation to each instance.
* Apply the Wilcoxon test to each taxon for each simulated instance.
* Estimate the effect size as the difference between conditions divided by the maximum difference within conditions averaging over all instances. Scaling the between group difference by the maximum within group difference gives us a standardized effect size measure. 
* Obtain the expected p-values for each taxon by averaging over all instances.
* Apply the BH-FDR correction to control the false positive rate.

For a more through explanation see the [ALDEx2 Bioconductor vignette](https://www.bioconductor.org/packages/release/bioc/vignettes/ALDEx2/inst/doc/ALDEx2_vignette.pdf). 

Lets give it a try.


``` {r aldex2}
#Run ALDEx2
aldex2_da <- ALDEx2::aldex(data.frame(phyloseq::otu_table(ps)), phyloseq::sample_data(ps)$Status, test="t", effect = TRUE, denom="iqlr")

#Plot effect sizes
ALDEx2::aldex.plot(aldex2_da, type="MW", test="wilcox", called.cex = 1, cutoff = 0.05)


```

The output highlights the various steps for the ALDEx2 workflow. The interquartile log-ratio (iqlr) centering uses as the basis for the CLR transform the set of features that have variance values that fall between the first and third quartiles for all features in all groups in the dataset. This provides results that are more robust to asymmetric features between groups. 

The effect size plot shows the median log2 fold difference by the median log2 dispersion. This is a measure of the effect size by the variability. Differentially abundant taxon will be those where the difference most exceeds the dispersion. Points toward the top of the figure are more abundant in CF samples while those towards the bottom are more abundant in healthy controls. Taxa with BH-FDR corrected p-values are shown in red. However, the authors state that:
   
>We prefer to use the effect size whenever possible rather than statistical significance since an effect size tells the scientist what they want to know—“what is reproducibly different between groups”; this is emphatically not something that P values deliver.

Now we will print the output with the taxonomic classifications appended. WE use the FDR p-values here to facilitate the comparison with the results from Wilcoxon test ran outside of ALDEx2.


``` {r aldex2 df}
#Clean up presentation
sig_aldex2 <- aldex2_da %>%
  rownames_to_column(var = "OTU") %>%
  filter(wi.eBH < 0.05) %>%
  arrange(effect, wi.eBH) %>%
  dplyr::select(OTU, diff.btw, diff.win, effect, wi.ep, wi.eBH)

sig_aldex2 <- left_join(sig_aldex2, taxa_info)
sig_aldex2

```

Here we see that again that several Clostridiales organisms are identified as differentially abundant. Consistent with the results of running the Wilcoxon test outside of ALDEx2, we see that OTU48, OTU38, OTU44, and OTU8 are listed as differentially abundant. The others do not reach the FDR cut-off used here; although, they likely have "largish" effect sizes. *Try and see if you can obtain these values.* The reason for the discrepancy is hard to discern, but may be related to differences in the use of the CLR basis (geometric mean of all taxa versus the IQLR) and/or the use of the Bayesian resampling with a non-zero prior.  

Often, if I consider performing DA testing, **I will run several models and focus on the intersection of OTUs** and try to gain some insight into how the different normalization and/or models many be influencing the results.  


There are **MANY** other approaches that can be used to attempt to identify differently abundant taxa.  Some that are popular, or that I find interesting, and can be implemented in R include:

  * Count Regression for Correlated Observations with the Beta-binomial [(corncob)](https://github.com/bryandmartin/corncob)
  * [MicrobiomeDDA](https://academic.oup.com/bioinformatics/article/34/4/643/4470360)
  * [DESeq2](https://joey711.github.io/phyloseq-extensions/DESeq2.html)
  * [Analysis of Composition of Microbiomes (ANCOM)](https://sites.google.com/site/siddharthamandal1985/research)


Outside of R, a recently developed approach using [multinomial regression via tensorflow](https://github.com/biocore/songbird) and differential ranking looks promising.  


<br>



# Prediction

As discussed by Dr. Haslam in the first lecture, the majority of clinical microbiome studies, conducted to date, have been correlative or focused on predicting outcomes using taxonomic abundances as the feature set. **The predictive utility of the human microbiome in health and disease is of great interest** and numerous studies have reported the ability to predict outcomes from metagenomic data. For example, here are links to three studies suggesting taxonomic profiles in fecal samples may predict the occurrence of colorectal cancer ([1](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5989068/), [2](https://www.nature.com/articles/s41591-019-0405-7), [3](https://www.nature.com/articles/s41591-019-0406-6)). 

As with differential abundance testing, there are many models or statistical learning approaches that can be applied to metagenomic data for the purpose of predicting an outcome. For binary outcomes, generating predicted probabilities for the outcome of interest using generalized linear models (GLMs) is one approach. Machine learning approaches have also been used extensively in microbiome research; however, these approaches may likely require much larger datasets than they have typically been trained on if our goal is reproducible results (the same likely goes for most studies using GLMs, etc.). 

One challenge we face when building a predictive model from metagenomic data is that **we often have more features (taxon) than we have samples.**  For example, if we are working with microbial strains we might have more than 10,000 features to consider. One way to define high-dimensional data is when *p* > *n*, where: p = number of features and n = the number of samples. In these instances, one approach forward to reduce the dimensionality of the data. We did this earlier when we used PCA to extract the first two PCs that explained the largest fraction of variably in our data. Using a subset of the PCs as predictors in a GLM is known as principal components regression. We will give this approach a try below. Another is to include all the features as predictors, but to shrink their effects towards zero (or sometimes shrink them entirely out of the model).  These approaches go by names such as ridge regression, LASSO, elastic nets, etc. Bayesian models with skeptical priors also can work well here. We will use a form of penalization on the principal components regression model below to highlight this approach and address potential overfitting even with just three PCs at this sample size (which is likely too small for robust prediction). A helpful guide to think about how many features or samples one might require to develop a predictive model is to consider how much overfitting you are willing to accept. Here are links to two excellent papers describing sample size determinations for [continuous](https://onlinelibrary.wiley.com/doi/full/10.1002/sim.7993) and [binary](https://onlinelibrary.wiley.com/doi/full/10.1002/sim.7992) outcomes in predictive modeling.

We will also examine a CoDA greedy stepwise selection model using balances that I think is a lot of fun...and very user-friendly.

For those interested in general resources for prediction modeling I recommend:

  * Frank Harrell's Regression Modeling Stratagies [website](http://biostat.mc.vanderbilt.edu/wiki/Main/RmS) and [textbook](https://www.springer.com/us/book/9783319194240#aboutBook)
  * Ewout Steyerberg's Clinical Prediction Models [textbook](https://www.springer.com/gp/book/9780387772431) for a bit more introductory text
  * Max Kuhn's Applied Predictive Modeling [textbook](http://appliedpredictivemodeling.com/)
  * James, Witten, Hastie, and Tibshirani's [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/)


First we will create a data.frame that contains the Status and the first 3 PCs from the centered-log ratio transformed abundance table we generated before. We will then plot the unconditional association for each PC with the outcome of CF versus control.

```{r plot pcs}

#Generate data.frame
clr_pcs <- data.frame(
  "pc1" = ord_clr$CA$u[,1],
  "pc2" = ord_clr$CA$u[,2],
  "pc3" = ord_clr$CA$u[,3],
  "Status" = phyloseq::sample_data(ps_clr)$Status
)

clr_pcs$Status_num <- ifelse(clr_pcs$Status == "Control", 0, 1)
head(clr_pcs)

#Specify a datadist object (for rms)
dd <- datadist(clr_pcs)
options(datadist = "dd")


#Plot the unconditional associations
a <- ggplot(clr_pcs, aes(x = pc1, y = Status_num)) +
  Hmisc::histSpikeg(Status_num ~ pc1, lowess = TRUE, data = clr_pcs) +
  labs(x = "\nPC1", y = "Pr(Chronic Fatigue)\n")

b <- ggplot(clr_pcs, aes(x = pc2, y = Status_num)) +
  Hmisc::histSpikeg(Status_num ~ pc2, lowess = TRUE, data = clr_pcs) +
  labs(x = "\nPC2", y = "Pr(Chronic Fatigue)\n")

c <- ggplot(clr_pcs, aes(x = pc3, y = Status_num)) +
  Hmisc::histSpikeg(Status_num ~ pc3, lowess = TRUE, data = clr_pcs) +
  labs(x = "\nPC3", y = "Pr(Chronic Fatigue)\n")

cowplot::plot_grid(a, b, c, nrow = 2, ncol = 2, scale = .9, labels = "AUTO")

```


We see that we have the potential for some non-linear associations. Professor Harrell recommends that it is generally a good idea to assume some level of complexity since the penalty for allowing for a non-linear fit, when the association is in fact linear, is much less than when assuming linearity when the association is non-linear (i.e. you fit a straight line through a u-shaped curve).  His [rms package]( https://cran.r-project.org/web/packages/rms/index.html), along with the tidyverse, are the two packages I use most often and allows us to model this type of complexity easily using [restricted cubic splines](https://towardsdatascience.com/restricted-cubic-splines-c0617b07b9a5). These are a set of highly flexible, smoothly joined, piecewise polynomials entered for each variable. The number and placement of the knots helps control the flexibility.  We will allow three knots for each term.  However, this results in an additional 3 (6 total) model degrees of freedom…but we will shrink this down.  

We first fit the full model and then perform a grid search to identify the optimum value for the penalty. We can also allow the penalty to differ for the simple and complex (i.e. nonlinear or interactions) terms. This is helpful if we want to allow for complexity, but down weight its impact. This would kind of be like adding more restrictive priors to the non-linear terms in a Bayesian model. We then plot the penalized log odds.
  

```{r rms lrm}

#Fit full model with splines (3 knots each)
m1 <- rms::lrm(Status_num ~ rcs(pc1, 3) + rcs(pc2, 3) + rcs(pc3, 3), data = clr_pcs, x = TRUE, y = TRUE)

#Grid search for penalties
pentrace(m1, list(simple = c(0, 1, 2), nonlinear = c(0, 100, 200)))
pen_m1 <- update(m1, penalty = list(simple = 1, nonlinear = 200))
pen_m1

#Plot log odds
ggplot(Predict(pen_m1))

```

We can see from the value of the penalties and the resultant log odds that the conditional associations are quite linear.  However, we will leave in the cubic spline terms to fully account for the degrees of freedom we entertained in the model building process. The optimal penalties were 1 for the simple and 200 for the non-linear terms (higher is better for the corrected AIC) and the effective degrees of freedom shrunk to 2.78. We won't interpret the coefficients here since we purposefully biased them towards zero. 

The [Brier score](https://en.wikipedia.org/wiki/Brier_score) is 0.16 and provides a measure of the mean squared difference between the predicted probabilities and actual outcomes. Thus, it is a quadratic proper scoring rule. The c-statistic is analogous to the area under the receiver operating characteristic curve and is a measure of rank discrimination. Here it is c = 0.85.  


<br>

No we will perform bootstrap resampling to obtain an out-of-sample estimate of model performance. Here is a [link describing this in greater detail](https://thestatsgeek.com/2014/10/04/adjusting-for-optimismoverfitting-in-measures-of-predictive-ability-using-bootstrapping/).



```{r rms val}
#Obtain optimism corrected estimates
(val <- rms::validate(pen_m1))

#Compute corrected c-statistic
(c_opt_corr <- 0.5 * (val[1, 5] + 1))

#Plot calibration
cal <- rms::calibrate(pen_m1, B = 200)
plot(cal)

#Output pred. probs
head(predict(pen_m1, type ="fitted"))

```

We can see here that the Brier score is only mildly increased, and the c-statistic mildly decreased with repeated resampling. The calibration curve shows that the predictions are near the ideal across the range of predicted values. All-in-all this suggests we may expect to be able to predict patients with chronic fatigue from healthy controls with reasonable accuracy in a new sample of patients drawn from a similar population using just the three top PCs.    

<br>


**Now we will quickly show selbal as an alternaitve.** From the documentation selbal is described as:

>selbal is an R package for selection of balances in microbiome compositional data. As described in Rivera-Pinto et al. 2018 Balances: a new perspective for microbiome analysis https://doi.org/10.1101/219386, selbal implements a forward-selection method for the identification of two groups of taxa whose relative abundance, or balance, is associated with the response variable of interest.

It requires much less typing...so let's give it a go. This approach is computationally expensive (especially with larger datasets).  So below we only use 1 repeat of 5-fold cross-validation to tune the selections.  In practice, we would want to turn these numbers up to get better estimates. We will also aggregate the taxa to the family-level to speed up the computation.


```{r selbal, fig.height = 8, fig.width = 14, fig.align = "center"}
#Agglomerate taxa
(ps_family <- phyloseq::tax_glom(ps, "Family"))
phyloseq::taxa_names(ps_family) <- phyloseq::tax_table(ps_family)[, "Family"]

#Run selbal
cv_sebal <- selbal::selbal.cv(x = data.frame(t(data.frame(phyloseq::otu_table(ps_family)))), 
                              y = phyloseq::sample_data(ps_family)$Status, 
                              n.fold = 5, n.iter = 1)                             


#plot/print results
cv_sebal$accuracy.nvar
plot.new()
grid.draw(cv_sebal$global.plot)
```

Here we can see that the cross-validation selected the two balance object as having "among" the best rank-discrimination. It selected the balance with erysipelotrichaceae in the numerator and bifidobacteriaceae in the denominator.  So a higher relative abundance of erysipelotrichaceae to bifidobacteriaceae was among the most informative balances. The AUC was 0.77, but as low as AUC = 0.68 with 1 repeat of 5 fold cross-validation. 

**Give the model a try on the full ps object on your own.**  It should run in ~5 min on a standard laptop. *How does the performance compare?  Would you expect these results to be as reproducible as the GLM we fit?  Why?*

**That concludes this session. Check my GitHub page for updates and expanded examples.** 


